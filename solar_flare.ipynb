{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Solar+Flare v1.0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "def cargar_datos(ruta):\n",
    "    df = pd.read_csv(ruta, sep=r'\\s+', header=None, skiprows=1).to_numpy()\n",
    "    datos = np.array([fila[:10] for fila in df])\n",
    "    clase = np.array([fila[-3:] for fila in df])\n",
    "    return datos, clase\n",
    "\n",
    "def codificar_datos(datos):\n",
    "    label_encoders = []\n",
    "    for i in range(datos.shape[1]):\n",
    "        if isinstance(datos[0, i], str):\n",
    "            le = LabelEncoder()\n",
    "            datos[:, i] = le.fit_transform(datos[:, i])\n",
    "            label_encoders.append(le)\n",
    "        else:\n",
    "            label_encoders.append(None)\n",
    "    datos = datos.astype(int)\n",
    "    return datos, label_encoders\n",
    "\n",
    "ruta_local = \"solar+flare/flare.data2\"\n",
    "\n",
    "try:\n",
    "    datos, clase = cargar_datos(ruta_local)\n",
    "    datos, label_encoders = codificar_datos(datos)\n",
    "    for j in range(clase.shape[1]):\n",
    "        if isinstance(clase[0, j], str):\n",
    "            le = LabelEncoder()\n",
    "            clase[:, j] = le.fit_transform(clase[:, j])\n",
    "    clase = clase.astype(int)\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error al leer el archivo: {e}\")\n",
    "\n",
    "datos_entrena, datos_prueba, clase_entrena, clase_prueba = train_test_split(datos, clase, test_size=0.2)\n",
    "\n",
    "scaler = StandardScaler() \n",
    "datos_entrena = scaler.fit_transform(datos_entrena) \n",
    "datos_prueba = scaler.transform(datos_prueba)\n",
    "\n",
    "modelo = MultiOutputClassifier(LogisticRegression(max_iter=200))\n",
    "modelo.fit(datos_entrena, clase_entrena)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "predicción = modelo.predict(datos_prueba)\n",
    "\n",
    "for col, le in enumerate(label_encoders):\n",
    "    if le is not None:\n",
    "        print(f\"Columna {col+1} clases: {le.classes_}\")\n",
    "\n",
    "print(\"Porcentaje de aciertos:\", modelo.score(datos_prueba, clase_prueba))\n",
    "print(\"\\n\", predicción)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Solar+Flare v2.0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "nombres_columnas = [\"modified Zurich class\", \"largest spot size\", \"spot distribution\", \n",
    "                    \"activity\", \"evolution\", \"previous 24 hour flare activity\", \n",
    "                    \"historically-complex\", \"became complex on this pass\", \n",
    "                    \"area\", \"area of largest spot\", \"common flares\", \n",
    "                    \"moderate flares\", \"severe flares\"]\n",
    "\n",
    "df = pd.read_csv(\"solar+flare/flare.data2\", sep=r'\\s+', header=None, skiprows=1, names=nombres_columnas)\n",
    "\n",
    "#df.info()\n",
    "\n",
    "df[\"modified Zurich class\"] = df[\"modified Zurich class\"].astype(\"category\")\n",
    "df[\"largest spot size\"] = df[\"largest spot size\"].astype(\"category\")\n",
    "df[\"spot distribution\"] = df[\"spot distribution\"].astype(\"category\")\n",
    "\n",
    "df_categorico = df[[\"modified Zurich class\", \"largest spot size\", \"spot distribution\"]]\n",
    "\n",
    "codificador = OneHotEncoder()\n",
    "codificacion = codificador.fit_transform(df_categorico)\n",
    "\n",
    "nuevas_columnas = pd.DataFrame(codificacion.toarray(), columns=codificador.get_feature_names_out(df_categorico.columns))\n",
    "\n",
    "df = df.drop([\"modified Zurich class\", \"largest spot size\", \"spot distribution\"], axis=\"columns\")\n",
    "df = pd.concat([df, nuevas_columnas], axis=\"columns\")\n",
    "\n",
    "clase = df[[\"common flares\", \"moderate flares\", \"severe flares\"]].to_numpy()\n",
    "datos = df.drop(columns=[\"common flares\", \"moderate flares\", \"severe flares\"]).to_numpy()\n",
    "\n",
    "datos_entrena, datos_prueba, clase_entrena, clase_prueba = train_test_split(datos, clase, test_size=0.30)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "datos_entrena = scaler.fit_transform(datos_entrena) \n",
    "datos_prueba = scaler.transform(datos_prueba)\n",
    "\n",
    "modelo = MultiOutputClassifier(LogisticRegression(max_iter=1000, solver='saga'))\n",
    "modelo.fit(datos_entrena, clase_entrena)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "predicciones = modelo.predict(datos_prueba)\n",
    "print(f'Precisión del modelo: {modelo.score(datos_prueba, clase_prueba)}\\n')\n",
    "\n",
    "predicciones_df = pd.DataFrame(predicciones, columns=[\"common flares (Pred)\", \"moderate flares (Pred)\", \"severe flares (Pred)\"])\n",
    "clase_prueba_df = pd.DataFrame(clase_prueba, columns=[\"common flares (Real)\", \"moderate flares (Real)\", \"severe flares (Real)\"])\n",
    "comparacion = pd.concat([clase_prueba_df.reset_index(drop=True), predicciones_df.reset_index(drop=True)], axis=1)\n",
    "comparacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Métricas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (confusion_matrix, accuracy_score, precision_score, recall_score, f1_score)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "for i, output in enumerate([\"common flares\", \"moderate flares\", \"severe flares\"]):\n",
    "    print(f\"Métricas para {output}:\")\n",
    "    \n",
    "    accuracy = accuracy_score(clase_prueba[:, i], predicciones[:, i])\n",
    "    precision = precision_score(clase_prueba[:, i], predicciones[:, i], average='macro', zero_division=0)\n",
    "    recall = recall_score(clase_prueba[:, i], predicciones[:, i], average='macro', zero_division=0)\n",
    "    f1 = f1_score(clase_prueba[:, i], predicciones[:, i], average='macro', zero_division=0)\n",
    "    \n",
    "    print(f\"Exactitud: {accuracy}\")\n",
    "    print(f\"Precisión: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "\n",
    "    conf_matrix = confusion_matrix(clase_prueba[:, i], predicciones[:, i])\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.title(f\"Matriz de Confusión para {output}\")\n",
    "    plt.xlabel(\"Predicciones\")\n",
    "    plt.ylabel(\"Reales\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
